<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="msapplication-config" content="/images/browserconfig.xml">
  <meta name="google-site-verification" content="XgZjCjedxF82a4b0z1Nr0FiopL5MQKta4RZweqPZaBY">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"note.siwei.info","root":"/","scheme":"Gemini","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Gradient Descent for linear regression taskData pre processing Load data from csv file to a list  12345trainDataList &#x3D; list()with open(&quot;train.csv&quot;, newline&#x3D;&quot;&quot;) as csvfile:    trainData &#x3D; csv.reader(cs">
<meta property="og:type" content="article">
<meta property="og:title" content="ML 2017 fall homework1 Linear Regression 笔记">
<meta property="og:url" content="https://note.siwei.info/ML-2017-fall-HW1-note/index.html">
<meta property="og:site_name" content="Siwei notes">
<meta property="og:description" content="Gradient Descent for linear regression taskData pre processing Load data from csv file to a list  12345trainDataList &#x3D; list()with open(&quot;train.csv&quot;, newline&#x3D;&quot;&quot;) as csvfile:    trainData &#x3D; csv.reader(cs">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_lr_tunning_1.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_lr_tunning_2_10to20.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_lr_tunning_2_0to32.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_lr_tunning_2_last25_after_33.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_lr_tunning_2_after_33_to200.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_lr_tunning_207_388_doubleLR.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_yW391_yW396_yAnswer.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_L_adagrad_vs_BGD_390.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_L_adagrad_vs_BGD_30.png">
<meta property="og:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_yBGD_yADAGRAD_yAnswer.png">
<meta property="article:published_time" content="2018-05-27T16:31:07.000Z">
<meta property="article:modified_time" content="2018-06-11T12:56:46.000Z">
<meta property="article:author" content="Wey Gu | 古思为">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="homework">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://note.siwei.info/ML-2017-fall-HW1-note/Figure_lr_tunning_1.png">

<link rel="canonical" href="https://note.siwei.info/ML-2017-fall-HW1-note/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>ML 2017 fall homework1 Linear Regression 笔记 | Siwei notes</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Siwei notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">思为笔记</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-résumé">

    <a href="/about/resume.pdf" rel="section"><i class="fa fa-fw fa-book"></i>Résumé</a>

  </li>
        <li class="menu-item menu-item-简历">

    <a href="/about/resume_chs.pdf" rel="section"><i class="fa fa-fw fa-book"></i>简历</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags<span class="badge">23</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories<span class="badge">3</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives<span class="badge">13</span></a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-fw fa-heartbeat"></i>Commonweal 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="default">
    <link itemprop="mainEntityOfPage" href="https://note.siwei.info/ML-2017-fall-HW1-note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Wey Gu | 古思为">
      <meta itemprop="description" content="Build things.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Siwei notes">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ML 2017 fall homework1 Linear Regression 笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-05-28 00:31:07" itemprop="dateCreated datePublished" datetime="2018-05-28T00:31:07+08:00">2018-05-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-06-11 20:56:46" itemprop="dateModified" datetime="2018-06-11T20:56:46+08:00">2018-06-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning-notes/" itemprop="url" rel="index"><span itemprop="name">machine learning notes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Gradient-Descent-for-linear-regression-task"><a href="#Gradient-Descent-for-linear-regression-task" class="headerlink" title="Gradient Descent for linear regression task"></a>Gradient Descent for linear regression task</h1><h2 id="Data-pre-processing"><a href="#Data-pre-processing" class="headerlink" title="Data pre processing"></a>Data pre processing</h2><ul>
<li>Load data from csv file to a list</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">trainDataList = list()</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"train.csv"</span>, newline=<span class="string">""</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line">    trainData = csv.reader(csvfile, delimiter=<span class="string">","</span>,quotechar=<span class="string">"|"</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> trainData:</span><br><span class="line">        trainDataList.append(line[<span class="number">3</span>:])</span><br></pre></td></tr></table></figure>

<ul>
<li><p>make all train data in one list, to enable iterating per hour of the list, thus, we have <code>(24 * days - 10 + 1)</code> training data.</p>
<p><code>trainDataIteratedPerHour: list()</code></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># n lines to be one day</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mod_18</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> n % <span class="number">18</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># transpose a matrix(2D list)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">T_list</span><span class="params">(l)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.array(l).T.tolist()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line">trainDataIteratedPerHour = []</span><br><span class="line">listToAppend = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> trainDataList[<span class="number">1</span>:]:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> mod_18(i):</span><br><span class="line">        <span class="comment"># from mod 10: 0</span></span><br><span class="line">        listToAppend = [item]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> mod_18(i) == <span class="number">10</span>:</span><br><span class="line">        <span class="comment"># rain, consider "NR" = 0</span></span><br><span class="line">        listToAppend.append([<span class="string">"0"</span> <span class="keyword">if</span> x == <span class="string">'NR'</span> <span class="keyword">else</span> x <span class="keyword">for</span> x <span class="keyword">in</span> item])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> mod_18(i) == <span class="number">17</span>:</span><br><span class="line">        <span class="comment"># all 18 lines collected, built a set of data to extend</span></span><br><span class="line">        listToAppend.append(item)</span><br><span class="line">        trainDataIteratedPerHour.extend(T_list(listToAppend))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># append other data</span></span><br><span class="line">        listToAppend.append(item)</span><br><span class="line">    i = i + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<ul>
<li>build <code>x_data</code> and <code>y_data</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">build x_data and y_data</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">x_data = [] <span class="comment"># 18*9 dimensions</span></span><br><span class="line">y_data = [] <span class="comment"># scalar, pm2.5 of next hour for x_data</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(len(trainDataIteratedPerHour) - <span class="number">10</span>):</span><br><span class="line">    x_data.extend(np.array(trainDataIteratedPerHour[n : n + <span class="number">9</span>]).reshape(<span class="number">1</span>,<span class="number">162</span>).tolist())</span><br><span class="line">    y_data.append(trainDataIteratedPerHour[n + <span class="number">10</span>][<span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">x_data = [[float(j) <span class="keyword">for</span> j <span class="keyword">in</span> i] <span class="keyword">for</span> i <span class="keyword">in</span> x_data]</span><br><span class="line">y_data = [float(i) <span class="keyword">for</span> i <span class="keyword">in</span> y_data]</span><br></pre></td></tr></table></figure>

<ul>
<li>draw plot (to feel the range of the data)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># draw plot of pm2.5 range?</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = range(len(y_data))</span><br><span class="line">y = np.array(y_data)</span><br><span class="line"><span class="comment"># refer to https://matplotlib.org/2.2.2/gallery/lines_bars_and_markers/simple_plot.html</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>



<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lossFunction</span><span class="params">(w, x_data, y_data)</span>:</span></span><br><span class="line">    w = np.array(w)</span><br><span class="line">    x_data = np.array(x_data)</span><br><span class="line">    result = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(y_data)):</span><br><span class="line">        result += (y_data[i] - sum(w * x_data[i]))**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># w = [0.01] * 162</span></span><br><span class="line"><span class="comment"># L = lossFunction(w,x_data,y_data)</span></span><br></pre></td></tr></table></figure>



<h2 id="Iterations-for-grident-descent"><a href="#Iterations-for-grident-descent" class="headerlink" title="Iterations for grident descent"></a>Iterations for grident descent</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Iterations</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iterationRun</span><span class="params">(lr,iteration,x_data,y_data)</span>:</span></span><br><span class="line">    <span class="comment"># initial data</span></span><br><span class="line">    w = [<span class="number">0.01</span>] * <span class="number">162</span></span><br><span class="line">    L_history = [lossFunction(w,x_data,y_data)]</span><br><span class="line"></span><br><span class="line">    w = np.array(w)</span><br><span class="line">    x_data = np.array(x_data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iterator <span class="keyword">in</span> range(iteration):</span><br><span class="line">        <span class="comment"># initialize w_grad</span></span><br><span class="line">        w_grad = [<span class="number">0.0</span>] * <span class="number">162</span></span><br><span class="line">        <span class="comment"># sum of all training data set</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> range(len(y_data)):</span><br><span class="line">            <span class="comment"># per feature</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">162</span>):</span><br><span class="line">                w_grad[i] = w_grad[i] - <span class="number">2.0</span> * x_data[n][i] * ( sum(w * x_data[n]) - y_data[n] )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update w</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">162</span>):</span><br><span class="line">            w[i] = w[i] + lr * w_grad[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># store Loss Function hisotry for plotting</span></span><br><span class="line">        L_history.append(lossFunction(w,x_data,y_data))</span><br><span class="line">        <span class="keyword">print</span> (str(iterator) + <span class="string">" : "</span> + str(datetime.datetime.now().time()) + <span class="string">" L:"</span> + str(L_history[<span class="number">-1</span>]))</span><br><span class="line">    <span class="keyword">return</span> L_history</span><br></pre></td></tr></table></figure>

<p>Run it for 10 iterations</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.0000000000001</span> <span class="comment"># learning rate</span></span><br><span class="line">iteration = <span class="number">10</span></span><br><span class="line">iterationRun(lr,iteration,x_data,y_data)</span><br></pre></td></tr></table></figure>



<h2 id="Tunning"><a href="#Tunning" class="headerlink" title="Tunning"></a>Tunning</h2><h3 id="Find-good-initial-learning-rate"><a href="#Find-good-initial-learning-rate" class="headerlink" title="Find good initial learning rate"></a>Find good initial learning rate</h3><p>start with <code>lr = 0.0000000000001</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">19</span>]: lr = <span class="number">0.0000000000001</span> <span class="comment"># learning rate</span></span><br><span class="line">    ...: iteration = <span class="number">10</span></span><br><span class="line">    ...: iterationRun(lr,iteration,x_data,y_data)</span><br><span class="line">    ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">13</span>:<span class="number">21</span>:<span class="number">22.227145</span> L:<span class="number">5897161.869645979</span></span><br><span class="line"><span class="number">1</span> : <span class="number">13</span>:<span class="number">21</span>:<span class="number">53.988814</span> L:<span class="number">5890818.193569232</span></span><br><span class="line"><span class="number">2</span> : <span class="number">13</span>:<span class="number">22</span>:<span class="number">25.639150</span> L:<span class="number">5884483.073933817</span></span><br><span class="line"><span class="number">3</span> : <span class="number">13</span>:<span class="number">22</span>:<span class="number">57.211950</span> L:<span class="number">5878156.49918669</span></span><br><span class="line"><span class="number">4</span> : <span class="number">13</span>:<span class="number">23</span>:<span class="number">28.873442</span> L:<span class="number">5871838.457790465</span></span><br><span class="line"><span class="number">5</span> : <span class="number">13</span>:<span class="number">24</span>:<span class="number">01.059230</span> L:<span class="number">5865528.93822318</span></span><br></pre></td></tr></table></figure>

<p>hmmm… try greater lr</p>
<p><code>lr = 0.00000000001</code></p>
<p>The loss function is descenting faster, like around 60000 per epoch.</p>
<a id="more"></a>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">21</span>]: lr = <span class="number">0.000000000001</span> <span class="comment"># learning rate</span></span><br><span class="line">    ...: iteration = <span class="number">10</span></span><br><span class="line">    ...: iterationRun(lr,iteration,x_data,y_data)</span><br><span class="line">    ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">13</span>:<span class="number">35</span>:<span class="number">09.910428</span> L:<span class="number">5840184.58334736</span></span><br><span class="line"><span class="number">1</span> : <span class="number">13</span>:<span class="number">35</span>:<span class="number">41.650901</span> L:<span class="number">5777706.652466557</span></span><br><span class="line"><span class="number">2</span> : <span class="number">13</span>:<span class="number">36</span>:<span class="number">13.323090</span> L:<span class="number">5716068.8576254565</span></span><br><span class="line"><span class="number">3</span> : <span class="number">13</span>:<span class="number">36</span>:<span class="number">45.001751</span> L:<span class="number">5655259.889673614</span></span><br><span class="line"><span class="number">4</span> : <span class="number">13</span>:<span class="number">37</span>:<span class="number">16.168479</span> L:<span class="number">5595268.591697776</span></span><br><span class="line"><span class="number">5</span> : <span class="number">13</span>:<span class="number">37</span>:<span class="number">47.701241</span> L:<span class="number">5536083.956972405</span></span><br><span class="line"><span class="number">6</span> : <span class="number">13</span>:<span class="number">38</span>:<span class="number">19.216952</span> L:<span class="number">5477695.126938047</span></span><br><span class="line"><span class="number">7</span> : <span class="number">13</span>:<span class="number">38</span>:<span class="number">51.013157</span> L:<span class="number">5420091.389206737</span></span><br></pre></td></tr></table></figure>

<p>our training set data is <code>5750</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">20</span>]: len(y_data)</span><br><span class="line">Out[<span class="number">20</span>]: <span class="number">5750</span></span><br></pre></td></tr></table></figure>

<p>If prediected pm 2.5 value , a.k.a y data is in error range 10, the L value should be <code>5750*100=575000</code></p>
<p>With current descent speed, we will need 88 epoch:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">24</span>]: (<span class="number">5840184</span><span class="number">-575000</span>)/<span class="number">60000</span></span><br><span class="line">Out[<span class="number">24</span>]: <span class="number">87.75306666666667</span></span><br></pre></td></tr></table></figure>

<p>let’s make it 10 times faster to see if target L could be get in 10 epoch</p>
<p><code>lr = 0.0000000001</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">27</span>]: lr = <span class="number">0.0000000001</span> <span class="comment"># learning rate</span></span><br><span class="line">    ...: iteration = <span class="number">10</span></span><br><span class="line">    ...: iterationRun(lr,iteration,x_data,y_data)</span><br><span class="line">    ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">13</span>:<span class="number">49</span>:<span class="number">10.609660</span> L:<span class="number">1692576.375268496</span></span><br><span class="line"><span class="number">1</span> : <span class="number">13</span>:<span class="number">49</span>:<span class="number">42.475991</span> L:<span class="number">1242849.9101765472</span></span><br><span class="line"><span class="number">2</span> : <span class="number">13</span>:<span class="number">50</span>:<span class="number">14.660518</span> L:<span class="number">1189717.4416525147</span></span><br><span class="line"><span class="number">3</span> : <span class="number">13</span>:<span class="number">50</span>:<span class="number">46.605178</span> L:<span class="number">1178550.5080278912</span></span><br><span class="line"><span class="number">4</span> : <span class="number">13</span>:<span class="number">51</span>:<span class="number">18.416010</span> L:<span class="number">1171963.6339294983</span></span><br><span class="line"><span class="number">5</span> : <span class="number">13</span>:<span class="number">51</span>:<span class="number">50.342550</span> L:<span class="number">1166008.2433918654</span></span><br><span class="line"><span class="number">6</span> : <span class="number">13</span>:<span class="number">52</span>:<span class="number">22.022203</span> L:<span class="number">1160260.444018784</span></span><br><span class="line"><span class="number">7</span> : <span class="number">13</span>:<span class="number">52</span>:<span class="number">53.942997</span> L:<span class="number">1154668.3447938378</span></span><br><span class="line"><span class="number">8</span> : <span class="number">13</span>:<span class="number">53</span>:<span class="number">25.925997</span> L:<span class="number">1149219.7383900573</span></span><br><span class="line"><span class="number">9</span> : <span class="number">13</span>:<span class="number">53</span>:<span class="number">57.718994</span> L:<span class="number">1143907.0426408767</span></span><br><span class="line">Out[<span class="number">27</span>]:</span><br><span class="line">[<span class="number">5903514.1137326835</span>,</span><br><span class="line"> <span class="number">1692576.375268496</span>,</span><br><span class="line"> <span class="number">1242849.9101765472</span>,</span><br><span class="line"> <span class="number">1189717.4416525147</span>,</span><br><span class="line"> <span class="number">1178550.5080278912</span>,</span><br><span class="line"> <span class="number">1171963.6339294983</span>,</span><br><span class="line"> <span class="number">1166008.2433918654</span>,</span><br><span class="line"> <span class="number">1160260.444018784</span>,</span><br><span class="line"> <span class="number">1154668.3447938378</span>,</span><br><span class="line"> <span class="number">1149219.7383900573</span>,</span><br><span class="line"> <span class="number">1143907.0426408767</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot it </span></span><br><span class="line">x = range(iteration+<span class="number">1</span>)</span><br><span class="line">y = np.array(L_history)</span><br><span class="line"><span class="comment"># refer to https://matplotlib.org/2.2.2/gallery/lines_bars_and_markers/simple_plot.html</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(x, y)</span><br></pre></td></tr></table></figure>

<img src="/ML-2017-fall-HW1-note/Figure_lr_tunning_1.png" class="">

<p>As we printed in first step only, we can see now the learning rate is way faster in initial step thus the first L printed is in smaller range!</p>
<p>And we also know it’s descenting slower after 10 ephoch, thus it’s not reaching our target <code>575000</code> in small steps.</p>
<p>I (for sure) know that I need to use adaptive learning rate and customised learning rate per feature(adagrade/ adam), while before that, I would like to see how it goes with smaller learning rate, while it goes to mess!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">46</span>]: lr = <span class="number">0.000000001</span> <span class="comment"># learning rate</span></span><br><span class="line">    ...: iteration = <span class="number">10</span></span><br><span class="line">    ...: iterationRun(lr,iteration,x_data,y_data)</span><br><span class="line">    ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">14</span>:<span class="number">09</span>:<span class="number">17.516243</span> L:<span class="number">156704618.55348668</span></span><br><span class="line"><span class="number">1</span> : <span class="number">14</span>:<span class="number">09</span>:<span class="number">49.509213</span> L:<span class="number">5150723049.19715</span></span><br><span class="line"><span class="number">2</span> : <span class="number">14</span>:<span class="number">10</span>:<span class="number">21.436315</span> L:<span class="number">170469039390.23218</span></span><br><span class="line"><span class="number">3</span> : <span class="number">14</span>:<span class="number">10</span>:<span class="number">53.396840</span> L:<span class="number">5642995478812.637</span></span><br></pre></td></tr></table></figure>

<h3 id="lr-1e-10"><a href="#lr-1e-10" class="headerlink" title="lr = 1e-10"></a>lr = <code>1e-10</code></h3><p>Then we could back to last initial learning rate, let’s get the final <code>w</code> by adding <code>print (w)</code> in <code>iterationRun()</code> , also we add initial w as an argument to enable modified initial <code>w</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iterationRun</span><span class="params">(lr,iteration,x_data,y_data, w = [<span class="number">0.01</span>] * <span class="number">162</span>)</span>:</span></span><br><span class="line">    <span class="comment"># initial data</span></span><br><span class="line">    </span><br><span class="line">    L_history = [lossFunction(w,x_data,y_data)]</span><br><span class="line"></span><br><span class="line">    w = np.array(w)</span><br><span class="line">    x_data = np.array(x_data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iterator <span class="keyword">in</span> range(iteration):</span><br><span class="line">        <span class="comment"># initialize w_grad</span></span><br><span class="line">        w_grad = [<span class="number">0.0</span>] * <span class="number">162</span></span><br><span class="line">        <span class="comment"># sum of all training data set</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> range(len(y_data)):</span><br><span class="line">            <span class="comment"># per feature</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">162</span>):</span><br><span class="line">                w_grad[i] = w_grad[i] - <span class="number">2.0</span> * x_data[n][i] * ( sum(w * x_data[n]) - y_data[n] )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update w</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">162</span>):</span><br><span class="line">            w[i] = w[i] + lr * w_grad[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># store Loss Function hisotry for plotting</span></span><br><span class="line">        L_history.append(lossFunction(w,x_data,y_data))</span><br><span class="line">        <span class="keyword">print</span> (str(iterator) + <span class="string">" : "</span> + str(datetime.datetime.now().time()) + <span class="string">" L:"</span> + str(L_history[<span class="number">-1</span>]))</span><br><span class="line">    <span class="keyword">print</span> (w)</span><br><span class="line">    <span class="keyword">return</span> L_history</span><br></pre></td></tr></table></figure>

<p>Then after re-run, we got the <code>w</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">49</span>]: lr = <span class="number">0.0000000001</span> <span class="comment"># learning rate</span></span><br><span class="line">    ...: iteration = <span class="number">10</span></span><br><span class="line">    ...: iterationRun(lr,iteration,x_data,y_data)</span><br><span class="line">    ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">14</span>:<span class="number">24</span>:<span class="number">45.664141</span> L:<span class="number">1692576.375268496</span></span><br><span class="line"><span class="number">1</span> : <span class="number">14</span>:<span class="number">25</span>:<span class="number">17.259352</span> L:<span class="number">1242849.9101765472</span></span><br><span class="line"><span class="number">2</span> : <span class="number">14</span>:<span class="number">25</span>:<span class="number">49.273630</span> L:<span class="number">1189717.4416525147</span></span><br><span class="line"><span class="number">3</span> : <span class="number">14</span>:<span class="number">26</span>:<span class="number">20.965149</span> L:<span class="number">1178550.5080278912</span></span><br><span class="line"><span class="number">4</span> : <span class="number">14</span>:<span class="number">26</span>:<span class="number">52.781849</span> L:<span class="number">1171963.6339294983</span></span><br><span class="line"><span class="number">5</span> : <span class="number">14</span>:<span class="number">27</span>:<span class="number">24.309887</span> L:<span class="number">1166008.2433918654</span></span><br><span class="line"><span class="number">6</span> : <span class="number">14</span>:<span class="number">27</span>:<span class="number">56.071350</span> L:<span class="number">1160260.444018784</span></span><br><span class="line"><span class="number">7</span> : <span class="number">14</span>:<span class="number">28</span>:<span class="number">27.729255</span> L:<span class="number">1154668.3447938378</span></span><br><span class="line"><span class="number">8</span> : <span class="number">14</span>:<span class="number">28</span>:<span class="number">59.185918</span> L:<span class="number">1149219.7383900573</span></span><br><span class="line"><span class="number">9</span> : <span class="number">14</span>:<span class="number">29</span>:<span class="number">31.678511</span> L:<span class="number">1143907.0426408767</span></span><br><span class="line">[<span class="number">0.00865451</span> <span class="number">0.00992088</span> <span class="number">0.00998412</span> <span class="number">0.00999356</span> <span class="number">0.00989859</span> <span class="number">0.00958899</span></span><br><span class="line"> <span class="number">0.00949017</span> <span class="number">0.00853832</span> <span class="number">0.00886119</span> <span class="number">0.00971015</span> <span class="number">0.00996496</span> <span class="number">0.00622562</span></span><br><span class="line"> <span class="number">0.00986532</span> <span class="number">0.00991454</span> <span class="number">0.00047019</span> <span class="number">0.0002918</span>  <span class="number">0.00985504</span> <span class="number">0.009888</span></span><br><span class="line"> <span class="number">0.00866327</span> <span class="number">0.00992104</span> <span class="number">0.00998492</span> <span class="number">0.00999403</span> <span class="number">0.00990841</span> <span class="number">0.00960856</span></span><br><span class="line"> <span class="number">0.00951873</span> <span class="number">0.00854217</span> <span class="number">0.00888944</span> <span class="number">0.00973543</span> <span class="number">0.00996355</span> <span class="number">0.00618855</span></span><br><span class="line"> <span class="number">0.00987026</span> <span class="number">0.00991514</span> <span class="number">0.00064165</span> <span class="number">0.00051266</span> <span class="number">0.00985705</span> <span class="number">0.00988871</span></span><br><span class="line"> <span class="number">0.00867558</span> <span class="number">0.00992112</span> <span class="number">0.00998615</span> <span class="number">0.00999456</span> <span class="number">0.00991583</span> <span class="number">0.00962887</span></span><br><span class="line"> <span class="number">0.00954697</span> <span class="number">0.00857636</span> <span class="number">0.00896101</span> <span class="number">0.00978193</span> <span class="number">0.00996072</span> <span class="number">0.00613156</span></span><br><span class="line"> <span class="number">0.00987708</span> <span class="number">0.0099157</span>  <span class="number">0.00089779</span> <span class="number">0.00075592</span> <span class="number">0.00985905</span> <span class="number">0.00988954</span></span><br><span class="line"> <span class="number">0.00869251</span> <span class="number">0.0099212</span>  <span class="number">0.00998776</span> <span class="number">0.00999517</span> <span class="number">0.009925</span>   <span class="number">0.00965916</span></span><br><span class="line"> <span class="number">0.00958656</span> <span class="number">0.00863933</span> <span class="number">0.00905468</span> <span class="number">0.00984584</span> <span class="number">0.00995951</span> <span class="number">0.00605779</span></span><br><span class="line"> <span class="number">0.00988265</span> <span class="number">0.00991644</span> <span class="number">0.0011024</span>  <span class="number">0.00105049</span> <span class="number">0.00986111</span> <span class="number">0.00989001</span></span><br><span class="line"> <span class="number">0.00871203</span> <span class="number">0.00992131</span> <span class="number">0.00998925</span> <span class="number">0.00999581</span> <span class="number">0.0099313</span>  <span class="number">0.00969443</span></span><br><span class="line"> <span class="number">0.00962812</span> <span class="number">0.00874158</span> <span class="number">0.00919581</span> <span class="number">0.00993813</span> <span class="number">0.00996109</span> <span class="number">0.00597563</span></span><br><span class="line"> <span class="number">0.00989311</span> <span class="number">0.00991724</span> <span class="number">0.00152071</span> <span class="number">0.00139776</span> <span class="number">0.00986338</span> <span class="number">0.00989169</span></span><br><span class="line"> <span class="number">0.00873482</span> <span class="number">0.00992151</span> <span class="number">0.00999107</span> <span class="number">0.00999641</span> <span class="number">0.00993875</span> <span class="number">0.00973362</span></span><br><span class="line"> <span class="number">0.00967406</span> <span class="number">0.00888077</span> <span class="number">0.00938529</span> <span class="number">0.01006057</span> <span class="number">0.00996181</span> <span class="number">0.00589041</span></span><br><span class="line"> <span class="number">0.00990578</span> <span class="number">0.00991814</span> <span class="number">0.00187297</span> <span class="number">0.00190307</span> <span class="number">0.00986629</span> <span class="number">0.00989357</span></span><br><span class="line"> <span class="number">0.00875685</span> <span class="number">0.00992174</span> <span class="number">0.00999275</span> <span class="number">0.00999693</span> <span class="number">0.0099442</span>  <span class="number">0.00977445</span></span><br><span class="line"> <span class="number">0.00972014</span> <span class="number">0.00904638</span> <span class="number">0.00964319</span> <span class="number">0.01023079</span> <span class="number">0.00996201</span> <span class="number">0.00581055</span></span><br><span class="line"> <span class="number">0.00992017</span> <span class="number">0.00991885</span> <span class="number">0.0023883</span>  <span class="number">0.0023404</span>  <span class="number">0.00986947</span> <span class="number">0.00989559</span></span><br><span class="line"> <span class="number">0.0087768</span>  <span class="number">0.009922</span>   <span class="number">0.00999477</span> <span class="number">0.00999745</span> <span class="number">0.00994748</span> <span class="number">0.00981834</span></span><br><span class="line"> <span class="number">0.0097673</span>  <span class="number">0.00922359</span> <span class="number">0.00995879</span> <span class="number">0.01041849</span> <span class="number">0.00995968</span> <span class="number">0.00574316</span></span><br><span class="line"> <span class="number">0.00993535</span> <span class="number">0.00991957</span> <span class="number">0.00290124</span> <span class="number">0.00287465</span> <span class="number">0.00987295</span> <span class="number">0.0098975</span></span><br><span class="line"> <span class="number">0.00879132</span> <span class="number">0.0099223</span>  <span class="number">0.00999638</span> <span class="number">0.00999786</span> <span class="number">0.00994411</span> <span class="number">0.00986186</span></span><br><span class="line"> <span class="number">0.0098075</span>  <span class="number">0.00938749</span> <span class="number">0.0103109</span>  <span class="number">0.0108169</span>  <span class="number">0.00995914</span> <span class="number">0.00570475</span></span><br><span class="line"> <span class="number">0.00995173</span> <span class="number">0.00992029</span> <span class="number">0.0036527</span>  <span class="number">0.00347423</span> <span class="number">0.00987645</span> <span class="number">0.00990038</span>]</span><br><span class="line">Out[<span class="number">49</span>]:</span><br><span class="line">[<span class="number">5903514.1137326835</span>,</span><br><span class="line"> <span class="number">1692576.375268496</span>,</span><br><span class="line"> <span class="number">1242849.9101765472</span>,</span><br><span class="line"> <span class="number">1189717.4416525147</span>,</span><br><span class="line"> <span class="number">1178550.5080278912</span>,</span><br><span class="line"> <span class="number">1171963.6339294983</span>,</span><br><span class="line"> <span class="number">1166008.2433918654</span>,</span><br><span class="line"> <span class="number">1160260.444018784</span>,</span><br><span class="line"> <span class="number">1154668.3447938378</span>,</span><br><span class="line"> <span class="number">1149219.7383900573</span>,</span><br><span class="line"> <span class="number">1143907.0426408767</span>]</span><br></pre></td></tr></table></figure>

<h3 id="Run-10-20-epoch-lr-1e-10"><a href="#Run-10-20-epoch-lr-1e-10" class="headerlink" title="Run 10~20 epoch, lr=1e-10"></a>Run 10~20 epoch, lr=<code>1e-10</code></h3><p>Another 10 epoch( continued from first 10 epoch):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#w = [] output value in initial 10 epoch</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: lr = <span class="number">0.0000000001</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: iteration = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: iterationRun(lr,iteration,x_data,y_data,w)</span><br><span class="line">    ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">14</span>:<span class="number">41</span>:<span class="number">55.554137</span> L:<span class="number">1138723.54416636</span></span><br><span class="line"><span class="number">1</span> : <span class="number">14</span>:<span class="number">42</span>:<span class="number">27.844246</span> L:<span class="number">1133663.0986562215</span></span><br><span class="line"><span class="number">2</span> : <span class="number">14</span>:<span class="number">42</span>:<span class="number">59.894751</span> L:<span class="number">1128719.8759725974</span></span><br><span class="line"><span class="number">3</span> : <span class="number">14</span>:<span class="number">43</span>:<span class="number">32.401907</span> L:<span class="number">1123888.4508929225</span></span><br><span class="line"><span class="number">4</span> : <span class="number">14</span>:<span class="number">44</span>:<span class="number">04.728092</span> L:<span class="number">1119163.74563917</span></span><br><span class="line"><span class="number">5</span> : <span class="number">14</span>:<span class="number">44</span>:<span class="number">36.823878</span> L:<span class="number">1114541.0056141382</span></span><br><span class="line"><span class="number">6</span> : <span class="number">14</span>:<span class="number">45</span>:<span class="number">08.958169</span> L:<span class="number">1110015.776899496</span></span><br><span class="line"><span class="number">7</span> : <span class="number">14</span>:<span class="number">45</span>:<span class="number">41.079041</span> L:<span class="number">1105583.8853543748</span></span><br><span class="line"><span class="number">8</span> : <span class="number">14</span>:<span class="number">46</span>:<span class="number">13.182146</span> L:<span class="number">1101241.4171967693</span></span><br><span class="line"><span class="number">9</span> : <span class="number">14</span>:<span class="number">46</span>:<span class="number">45.360379</span> L:<span class="number">1096984.7009616988</span></span><br><span class="line">[ <span class="number">8.39928810e-03</span>  <span class="number">9.92018594e-03</span>  <span class="number">9.98672249e-03</span>  <span class="number">9.99395695e-03</span></span><br><span class="line">  <span class="number">9.90650252e-03</span>  <span class="number">9.66028161e-03</span>  <span class="number">9.57133059e-03</span>  <span class="number">8.59024624e-03</span></span><br><span class="line">  <span class="number">9.70063031e-03</span>  <span class="number">1.04003048e-02</span>  <span class="number">9.94007211e-03</span>  <span class="number">5.82092975e-03</span></span><br><span class="line">  <span class="number">9.86818613e-03</span>  <span class="number">9.91420797e-03</span> <span class="number">-7.30043313e-04</span> <span class="number">-9.74984684e-04</span></span><br><span class="line">  <span class="number">9.81897077e-03</span>  <span class="number">9.85914945e-03</span>  <span class="number">8.42038505e-03</span>  <span class="number">9.92049552e-03</span></span><br><span class="line">  <span class="number">9.98824144e-03</span>  <span class="number">9.99488279e-03</span>  <span class="number">9.92479021e-03</span>  <span class="number">9.70246400e-03</span></span><br><span class="line">  <span class="number">9.63010828e-03</span>  <span class="number">8.61918398e-03</span>  <span class="number">9.77660141e-03</span>  <span class="number">1.04616680e-02</span></span><br><span class="line">  <span class="number">9.93740891e-03</span>  <span class="number">5.73728090e-03</span>  <span class="number">9.87953143e-03</span>  <span class="number">9.91540645e-03</span></span><br><span class="line"> <span class="number">-2.36708203e-04</span> <span class="number">-4.46497772e-04</span>  <span class="number">9.82369317e-03</span>  <span class="number">9.86089703e-03</span></span><br><span class="line">  <span class="number">8.44699272e-03</span>  <span class="number">9.92063613e-03</span>  <span class="number">9.99060846e-03</span>  <span class="number">9.99592360e-03</span></span><br><span class="line">  <span class="number">9.93769384e-03</span>  <span class="number">9.74480356e-03</span>  <span class="number">9.68631482e-03</span>  <span class="number">8.69975569e-03</span></span><br><span class="line">  <span class="number">9.93568798e-03</span>  <span class="number">1.05632875e-02</span>  <span class="number">9.93195597e-03</span>  <span class="number">5.62070493e-03</span></span><br><span class="line">  <span class="number">9.89358966e-03</span>  <span class="number">9.91648735e-03</span>  <span class="number">3.09727865e-04</span>  <span class="number">3.32769386e-05</span></span><br><span class="line">  <span class="number">9.82806229e-03</span>  <span class="number">9.86271172e-03</span>  <span class="number">8.48109217e-03</span>  <span class="number">9.92078753e-03</span></span><br><span class="line">  <span class="number">9.99374187e-03</span>  <span class="number">9.99713322e-03</span>  <span class="number">9.95409819e-03</span>  <span class="number">9.80638186e-03</span></span><br><span class="line">  <span class="number">9.76454663e-03</span>  <span class="number">8.82732248e-03</span>  <span class="number">1.01321537e-02</span>  <span class="number">1.06964648e-02</span></span><br><span class="line">  <span class="number">9.92985319e-03</span>  <span class="number">5.47712005e-03</span>  <span class="number">9.90438972e-03</span>  <span class="number">9.91794789e-03</span></span><br><span class="line">  <span class="number">6.73973650e-04</span>  <span class="number">5.44360035e-04</span>  <span class="number">9.83218649e-03</span>  <span class="number">9.86359313e-03</span></span><br><span class="line">  <span class="number">8.51878100e-03</span>  <span class="number">9.92099916e-03</span>  <span class="number">9.99667211e-03</span>  <span class="number">9.99839142e-03</span></span><br><span class="line">  <span class="number">9.96501744e-03</span>  <span class="number">9.87773770e-03</span>  <span class="number">9.84678838e-03</span>  <span class="number">9.02306858e-03</span></span><br><span class="line">  <span class="number">1.04158946e-02</span>  <span class="number">1.08835903e-02</span>  <span class="number">9.93324622e-03</span>  <span class="number">5.32255768e-03</span></span><br><span class="line">  <span class="number">9.92446485e-03</span>  <span class="number">9.91952209e-03</span>  <span class="number">1.38594142e-03</span>  <span class="number">1.10724366e-03</span></span><br><span class="line">  <span class="number">9.83633504e-03</span>  <span class="number">9.86671984e-03</span>  <span class="number">8.56162962e-03</span>  <span class="number">9.92140609e-03</span></span><br><span class="line">  <span class="number">1.00002676e-02</span>  <span class="number">9.99958471e-03</span>  <span class="number">9.97874755e-03</span>  <span class="number">9.95697261e-03</span></span><br><span class="line">  <span class="number">9.93834450e-03</span>  <span class="number">9.28329913e-03</span>  <span class="number">1.07901635e-02</span>  <span class="number">1.11284264e-02</span></span><br><span class="line">  <span class="number">9.93483699e-03</span>  <span class="number">5.16636435e-03</span>  <span class="number">9.94860271e-03</span>  <span class="number">9.92131553e-03</span></span><br><span class="line">  <span class="number">1.92598395e-03</span>  <span class="number">1.94810223e-03</span>  <span class="number">9.84148301e-03</span>  <span class="number">9.87004892e-03</span></span><br><span class="line">  <span class="number">8.60192082e-03</span>  <span class="number">9.92187479e-03</span>  <span class="number">1.00036215e-02</span>  <span class="number">1.00006191e-02</span></span><br><span class="line">  <span class="number">9.98884103e-03</span>  <span class="number">1.00394245e-02</span>  <span class="number">1.00304865e-02</span>  <span class="number">9.58954906e-03</span></span><br><span class="line">  <span class="number">1.12961891e-02</span>  <span class="number">1.14662940e-02</span>  <span class="number">9.93528449e-03</span>  <span class="number">5.02390839e-03</span></span><br><span class="line">  <span class="number">9.97597866e-03</span>  <span class="number">9.92274238e-03</span>  <span class="number">2.75467811e-03</span>  <span class="number">2.63288432e-03</span></span><br><span class="line">  <span class="number">9.84692043e-03</span>  <span class="number">9.87360657e-03</span>  <span class="number">8.63756441e-03</span>  <span class="number">9.92241075e-03</span></span><br><span class="line">  <span class="number">1.00076795e-02</span>  <span class="number">1.00016598e-02</span>  <span class="number">9.99478393e-03</span>  <span class="number">1.01275708e-02</span></span><br><span class="line">  <span class="number">1.01245597e-02</span>  <span class="number">9.91586834e-03</span>  <span class="number">1.19162061e-02</span>  <span class="number">1.18375866e-02</span></span><br><span class="line">  <span class="number">9.93069923e-03</span>  <span class="number">4.90773511e-03</span>  <span class="number">1.00047837e-02</span>  <span class="number">9.92420129e-03</span></span><br><span class="line">  <span class="number">3.57134262e-03</span>  <span class="number">3.51203380e-03</span>  <span class="number">9.85289824e-03</span>  <span class="number">9.87690267e-03</span></span><br><span class="line">  <span class="number">8.66241404e-03</span>  <span class="number">9.92304041e-03</span>  <span class="number">1.00109440e-02</span>  <span class="number">1.00024858e-02</span></span><br><span class="line">  <span class="number">9.98759482e-03</span>  <span class="number">1.02142033e-02</span>  <span class="number">1.02041105e-02</span>  <span class="number">1.02157481e-02</span></span><br><span class="line">  <span class="number">1.26087041e-02</span>  <span class="number">1.26296733e-02</span>  <span class="number">9.92961546e-03</span>  <span class="number">4.84886429e-03</span></span><br><span class="line">  <span class="number">1.00360505e-02</span>  <span class="number">9.92566063e-03</span>  <span class="number">4.87428673e-03</span>  <span class="number">4.54246885e-03</span></span><br><span class="line">  <span class="number">9.85895437e-03</span>  <span class="number">9.88225200e-03</span>]</span><br><span class="line">Out[<span class="number">61</span>]:</span><br><span class="line">[<span class="number">1143907.0116957787</span>,</span><br><span class="line"> <span class="number">1138723.54416636</span>,</span><br><span class="line"> <span class="number">1133663.0986562215</span>,</span><br><span class="line"> <span class="number">1128719.8759725974</span>,</span><br><span class="line"> <span class="number">1123888.4508929225</span>,</span><br><span class="line"> <span class="number">1119163.74563917</span>,</span><br><span class="line"> <span class="number">1114541.0056141382</span>,</span><br><span class="line"> <span class="number">1110015.776899496</span>,</span><br><span class="line"> <span class="number">1105583.8853543748</span>,</span><br><span class="line"> <span class="number">1101241.4171967693</span>,</span><br><span class="line"> <span class="number">1096984.7009616988</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: L_history = [<span class="number">1143907.0116957787</span>,</span><br><span class="line">    ...:  <span class="number">1138723.54416636</span>,</span><br><span class="line">    ...:  <span class="number">1133663.0986562215</span>,</span><br><span class="line">    ...:  <span class="number">1128719.8759725974</span>,</span><br><span class="line">    ...:  <span class="number">1123888.4508929225</span>,</span><br><span class="line">    ...:  <span class="number">1119163.74563917</span>,</span><br><span class="line">    ...:  <span class="number">1114541.0056141382</span>,</span><br><span class="line">    ...:  <span class="number">1110015.776899496</span>,</span><br><span class="line">    ...:  <span class="number">1105583.8853543748</span>,</span><br><span class="line">    ...:  <span class="number">1101241.4171967693</span>,</span><br><span class="line">    ...:  <span class="number">1096984.7009616988</span>]</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: x = range(iteration+<span class="number">1</span>)</span><br><span class="line">    ...: y = np.array(L_history)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: fig, ax = plt.subplots()</span><br><span class="line">    ...: ax.plot(x, y)</span><br><span class="line">    ...:</span><br><span class="line">Out[<span class="number">64</span>]: [&lt;matplotlib.lines.Line2D at <span class="number">0x1098122e8</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: plt.show()</span><br></pre></td></tr></table></figure>

<img src="/ML-2017-fall-HW1-note/Figure_lr_tunning_2_10to20.png" class="">

<p>The result is not bad! let’s continue</p>
<h3 id="Run-20-30-epoch-lr-1e-10"><a href="#Run-20-30-epoch-lr-1e-10" class="headerlink" title="Run 20-30 epoch, lr=1e-10"></a>Run 20-30 epoch, lr=<code>1e-10</code></h3><p>another 10 epoch</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">1e-10</span> <span class="comment"># learning rate</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Out[<span class="number">69</span>]:</span><br><span class="line">[<span class="number">1096984.7010237887</span>,</span><br><span class="line"> <span class="number">1092810.2907994157</span>,</span><br><span class="line"> <span class="number">1088714.9506539872</span>,</span><br><span class="line"> <span class="number">1084695.6401611501</span>,</span><br><span class="line"> <span class="number">1080749.50095292</span>,</span><br><span class="line"> <span class="number">1076873.8442235377</span>,</span><br><span class="line"> <span class="number">1073066.1391172102</span>,</span><br><span class="line"> <span class="number">1069324.0019368476</span>,</span><br><span class="line"> <span class="number">1065645.186115302</span>,</span><br><span class="line"> <span class="number">1062027.5728949562</span>,</span><br><span class="line"> <span class="number">1058469.162665172</span>]</span><br></pre></td></tr></table></figure>

<img src="/ML-2017-fall-HW1-note/Figure_lr_tunning_2_0to32.png" class="">

<p>Let’s zoom to last 25 epoch</p>
<img src="/ML-2017-fall-HW1-note/Figure_lr_tunning_2_last25_after_33.png" class="">

<p>We still have 1060000-575000 = 485000, and now te speed is like 3000 descent per epoch, which means we could reach target in 160 epoch if it keeps the same speed :-) (for sure it won’t).</p>
<h3 id="30-200-epoch-lr-1e-10"><a href="#30-200-epoch-lr-1e-10" class="headerlink" title="30~200 epoch, lr=1e-10"></a>30~200 epoch, lr=<code>1e-10</code></h3><p>When it run to 200 epoch, the L reached <code>809150.2256672443</code></p>
<img src="/ML-2017-fall-HW1-note/Figure_lr_tunning_2_after_33_to200.png" class="">

<h3 id="207-388-epoch-lr-2e-10"><a href="#207-388-epoch-lr-2e-10" class="headerlink" title="207~388 epoch, lr=2e-10"></a>207~388 epoch, lr=<code>2e-10</code></h3><p>This time let’s give lr as doubled, the initial speed is faster while it will end up with very slow, and after 180 epoch, L is <code>703824.3536660115</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">105</span>]: <span class="function"><span class="keyword">def</span> <span class="title">iterationRun</span><span class="params">(lr,iteration,x_data,y_data, w = [<span class="number">0.01</span>] * <span class="number">162</span>)</span>:</span></span><br><span class="line">     ...:     <span class="comment"># initial data</span></span><br><span class="line">     ...:</span><br><span class="line">     ...:     L_history = [lossFunction(w,x_data,y_data)]</span><br><span class="line">     ...:     W_history = [w]</span><br><span class="line">     ...:     w = np.array(w)</span><br><span class="line">     ...:     x_data = np.array(x_data)</span><br><span class="line">     ...:</span><br><span class="line">     ...:     <span class="keyword">for</span> iterator <span class="keyword">in</span> range(iteration):</span><br><span class="line">     ...:         <span class="comment"># initialize w_grad</span></span><br><span class="line">     ...:         w_grad = [<span class="number">0.0</span>] * <span class="number">162</span></span><br><span class="line">     ...:         <span class="comment"># sum of all training data set</span></span><br><span class="line">     ...:         <span class="keyword">for</span> n <span class="keyword">in</span> range(len(y_data)):</span><br><span class="line">     ...:             <span class="comment"># per feature</span></span><br><span class="line">     ...:             <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">162</span>):</span><br><span class="line">     ...:                 w_grad[i] = w_grad[i] - <span class="number">2.0</span> * x_data[n][i] * ( sum(w * x_data[n]) - y_data[n] )</span><br><span class="line">     ...:</span><br><span class="line">     ...:         <span class="comment"># update w</span></span><br><span class="line">     ...:         <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">162</span>):</span><br><span class="line">     ...:             w[i] = w[i] + lr * w_grad[i]</span><br><span class="line">     ...:</span><br><span class="line">     ...:         <span class="comment"># store Loss Function hisotry for plotting</span></span><br><span class="line">     ...:         L_history.append(lossFunction(w,x_data,y_data))</span><br><span class="line">     ...:         W_history.append(w[<span class="number">0</span>:])</span><br><span class="line">     ...:         <span class="keyword">print</span> (str(iterator) + <span class="string">" : "</span> + str(datetime.datetime.now().time()) + <span class="string">" L:"</span> + str(L_history[<span class="number">-1</span>]))</span><br><span class="line">     ...:     <span class="keyword">print</span> (w)</span><br><span class="line">     ...:     <span class="keyword">return</span> L_history, W_history</span><br><span class="line">     ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: lr = <span class="number">2e-10</span> <span class="comment"># learning rate</span></span><br><span class="line">     ...: iteration = <span class="number">180</span></span><br><span class="line">     ...: <span class="comment">#iterationRun(lr,iteration,x_data,y_data)</span></span><br><span class="line">     ...: <span class="comment">#w= &lt;last time&gt;</span></span><br><span class="line">     ...: L, W = iterationRun(lr,iteration,x_data,y_data,w)</span><br><span class="line">     ...: <span class="keyword">print</span> (str(L))</span><br><span class="line">     ...:</span><br></pre></td></tr></table></figure>



<img src="/ML-2017-fall-HW1-note/Figure_lr_tunning_207_388_doubleLR.png" class="">

<h3 id="388-391-epoch-lr-1e-8"><a href="#388-391-epoch-lr-1e-8" class="headerlink" title="388~ 391 epoch, lr =1e-8"></a>388~ 391 epoch, lr =<code>1e-8</code></h3><p>By tunning lr as we did in begining, it’s found <code>1e-8</code> can descent the L faster while <code>1e-7</code> will lead the value go mess:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">135</span>]: lr = <span class="number">1e-8</span> <span class="comment"># learning rate</span></span><br><span class="line">     ...: iteration = <span class="number">3</span></span><br><span class="line">     ...: <span class="comment">#iterationRun(lr,iteration,x_data,y_data)</span></span><br><span class="line">     ...: <span class="comment">#w= &lt;last time&gt;</span></span><br><span class="line">     ...: L, W = iterationRun(lr,iteration,x_data,y_data,w)</span><br><span class="line">     ...: <span class="keyword">print</span> (str(L))</span><br><span class="line">     ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">20</span>:<span class="number">36</span>:<span class="number">21.318040</span> L:<span class="number">688000.4130500836</span></span><br><span class="line"><span class="number">1</span> : <span class="number">20</span>:<span class="number">36</span>:<span class="number">50.809668</span> L:<span class="number">674508.5537428795</span></span><br><span class="line"><span class="number">2</span> : <span class="number">20</span>:<span class="number">37</span>:<span class="number">20.181931</span> L:<span class="number">662770.7844944517</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">136</span>]: lr = <span class="number">1e-7</span> <span class="comment"># learning rate</span></span><br><span class="line">     ...: iteration = <span class="number">3</span></span><br><span class="line">     ...: <span class="comment">#iterationRun(lr,iteration,x_data,y_data)</span></span><br><span class="line">     ...: <span class="comment">#w= &lt;last time&gt;</span></span><br><span class="line">     ...: L, W = iterationRun(lr,iteration,x_data,y_data,w)</span><br><span class="line">     ...: <span class="keyword">print</span> (str(L))</span><br><span class="line">     ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">20</span>:<span class="number">39</span>:<span class="number">52.192365</span> L:<span class="number">608540.3895276675</span></span><br><span class="line"><span class="number">1</span> : <span class="number">20</span>:<span class="number">40</span>:<span class="number">20.381015</span> L:<span class="number">784689.7603969924</span></span><br><span class="line"><span class="number">2</span> : <span class="number">20</span>:<span class="number">40</span>:<span class="number">49.856693</span> L:<span class="number">7013862.489781529</span></span><br></pre></td></tr></table></figure>

<p>Let’s do it with lr=<code>1e-8</code>, for another 20 epoch:</p>
<p>In the 0th~7th , L was normal while after from 4th epoch, the L goes crazy…</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">144</span>]: lr = <span class="number">1e-8</span> <span class="comment"># learning rate</span></span><br><span class="line">     ...: iteration = <span class="number">7</span></span><br><span class="line">     ...: <span class="comment">#iterationRun(lr,iteration,x_data,y_data)</span></span><br><span class="line">     ...: <span class="comment">#w= &lt;last time&gt;</span></span><br><span class="line">     ...: L, W = iterationRun(lr,iteration,x_data,y_data,w)</span><br><span class="line">     ...: <span class="keyword">print</span> (str(L))</span><br><span class="line">     ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">21</span>:<span class="number">05</span>:<span class="number">33.350228</span> L:<span class="number">688000.4130783302</span></span><br><span class="line"><span class="number">1</span> : <span class="number">21</span>:<span class="number">06</span>:<span class="number">02.751233</span> L:<span class="number">674508.5537976791</span></span><br><span class="line"><span class="number">2</span> : <span class="number">21</span>:<span class="number">06</span>:<span class="number">32.191330</span> L:<span class="number">662770.9045613626</span></span><br><span class="line"><span class="number">3</span> : <span class="number">21</span>:<span class="number">07</span>:<span class="number">01.596806</span> L:<span class="number">652980.2949830776</span></span><br><span class="line"><span class="number">4</span> : <span class="number">21</span>:<span class="number">07</span>:<span class="number">30.931137</span> L:<span class="number">2995810.210193815</span></span><br><span class="line"><span class="number">5</span> : <span class="number">21</span>:<span class="number">07</span>:<span class="number">58.316067</span> L:<span class="number">10415063655.932451</span></span><br><span class="line"><span class="number">6</span> : <span class="number">21</span>:<span class="number">08</span>:<span class="number">27.808302</span> L:<span class="number">46103934331702.31</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>below is a record for <em>w</em> in epoch 391 </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">171</span>]: lr = <span class="number">1e-8</span> <span class="comment"># learning rate</span></span><br><span class="line">     ...: iteration = <span class="number">3</span></span><br><span class="line">     ...: <span class="comment">#iterationRun(lr,iteration,x_data,y_data)</span></span><br><span class="line">     ...: <span class="comment">#w= &lt;last time&gt;</span></span><br><span class="line">     ...: L, W = iterationRun(lr,iteration,x_data,y_data,w)</span><br><span class="line">     ...: <span class="keyword">print</span> (str(L))</span><br><span class="line">     ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">21</span>:<span class="number">37</span>:<span class="number">21.649233</span> L:<span class="number">688000.4130783302</span></span><br><span class="line"><span class="number">1</span> : <span class="number">21</span>:<span class="number">37</span>:<span class="number">51.147582</span> L:<span class="number">674508.5537976791</span></span><br><span class="line"><span class="number">2</span> : <span class="number">21</span>:<span class="number">38</span>:<span class="number">21.861637</span> L:<span class="number">662770.9045613626</span></span><br><span class="line">[<span class="number">-0.00138578</span>  <span class="number">0.00996187</span>  <span class="number">0.00992188</span>  <span class="number">0.00993515</span>  <span class="number">0.00986949</span>  <span class="number">0.00805936</span></span><br><span class="line">  <span class="number">0.0080644</span>   <span class="number">0.00106609</span>  <span class="number">0.01072566</span>  <span class="number">0.02052564</span>  <span class="number">0.00912203</span>  <span class="number">0.00516551</span></span><br><span class="line">  <span class="number">0.00908692</span>  <span class="number">0.00989289</span> <span class="number">-0.00494451</span> <span class="number">-0.00553225</span>  <span class="number">0.00835639</span>  <span class="number">0.00869886</span></span><br><span class="line"> <span class="number">-0.00098925</span>  <span class="number">0.00997357</span>  <span class="number">0.00992211</span>  <span class="number">0.00995052</span>  <span class="number">0.01018278</span>  <span class="number">0.0086643</span></span><br><span class="line">  <span class="number">0.00890506</span>  <span class="number">0.00047888</span>  <span class="number">0.00890631</span>  <span class="number">0.02018968</span>  <span class="number">0.00904637</span>  <span class="number">0.00401723</span></span><br><span class="line">  <span class="number">0.00933431</span>  <span class="number">0.00991875</span>  <span class="number">0.00064744</span> <span class="number">-0.0033074</span>   <span class="number">0.00849263</span>  <span class="number">0.00874045</span></span><br><span class="line"> <span class="number">-0.00051749</span>  <span class="number">0.00997629</span>  <span class="number">0.00995735</span>  <span class="number">0.00997091</span>  <span class="number">0.01031358</span>  <span class="number">0.00907041</span></span><br><span class="line">  <span class="number">0.00948262</span>  <span class="number">0.00029924</span>  <span class="number">0.00947152</span>  <span class="number">0.02093619</span>  <span class="number">0.00880021</span>  <span class="number">0.00215371</span></span><br><span class="line">  <span class="number">0.00952237</span>  <span class="number">0.0099359</span>   <span class="number">0.00232706</span> <span class="number">-0.00298543</span>  <span class="number">0.00857945</span>  <span class="number">0.0087675</span></span><br><span class="line">  <span class="number">0.00012513</span>  <span class="number">0.00998106</span>  <span class="number">0.01003116</span>  <span class="number">0.01000607</span>  <span class="number">0.01077548</span>  <span class="number">0.01044418</span></span><br><span class="line">  <span class="number">0.01133557</span>  <span class="number">0.00046847</span>  <span class="number">0.01040126</span>  <span class="number">0.02224197</span>  <span class="number">0.00872205</span> <span class="number">-0.00046986</span></span><br><span class="line">  <span class="number">0.00953514</span>  <span class="number">0.0099784</span>   <span class="number">0.00020964</span> <span class="number">-0.00338643</span>  <span class="number">0.00863159</span>  <span class="number">0.0087242</span></span><br><span class="line">  <span class="number">0.00086619</span>  <span class="number">0.00999047</span>  <span class="number">0.01011715</span>  <span class="number">0.0100483</span>   <span class="number">0.0111914</span>   <span class="number">0.01258666</span></span><br><span class="line">  <span class="number">0.01390036</span>  <span class="number">0.00246372</span>  <span class="number">0.01393081</span>  <span class="number">0.02545522</span>  <span class="number">0.00884365</span> <span class="number">-0.00351077</span></span><br><span class="line">  <span class="number">0.00998476</span>  <span class="number">0.01003383</span>  <span class="number">0.00191473</span> <span class="number">-0.00361946</span>  <span class="number">0.0086276</span>   <span class="number">0.0087466</span></span><br><span class="line">  <span class="number">0.00184757</span>  <span class="number">0.01000815</span>  <span class="number">0.01025325</span>  <span class="number">0.01009751</span>  <span class="number">0.01193828</span>  <span class="number">0.0155177</span></span><br><span class="line">  <span class="number">0.01751577</span>  <span class="number">0.00667147</span>  <span class="number">0.02101305</span>  <span class="number">0.03113944</span>  <span class="number">0.00889165</span> <span class="number">-0.00695875</span></span><br><span class="line">  <span class="number">0.0106579</span>   <span class="number">0.01010881</span> <span class="number">-0.00077711</span> <span class="number">-0.00135554</span>  <span class="number">0.00866196</span>  <span class="number">0.00875398</span></span><br><span class="line">  <span class="number">0.00287227</span>  <span class="number">0.01003138</span>  <span class="number">0.01041372</span>  <span class="number">0.01014875</span>  <span class="number">0.01271766</span>  <span class="number">0.01906602</span></span><br><span class="line">  <span class="number">0.02182703</span>  <span class="number">0.01341795</span>  <span class="number">0.03354977</span>  <span class="number">0.0410597</span>   <span class="number">0.00883776</span> <span class="number">-0.01065909</span></span><br><span class="line">  <span class="number">0.01155844</span>  <span class="number">0.01017867</span>  <span class="number">0.00019663</span> <span class="number">-0.00158868</span>  <span class="number">0.0087129</span>   <span class="number">0.00877181</span></span><br><span class="line">  <span class="number">0.00398101</span>  <span class="number">0.01006115</span>  <span class="number">0.01063675</span>  <span class="number">0.01021088</span>  <span class="number">0.01347817</span>  <span class="number">0.02330813</span></span><br><span class="line">  <span class="number">0.02683348</span>  <span class="number">0.02287656</span>  <span class="number">0.05497111</span>  <span class="number">0.05429585</span>  <span class="number">0.00857217</span> <span class="number">-0.01436562</span></span><br><span class="line">  <span class="number">0.01264097</span>  <span class="number">0.01026398</span>  <span class="number">0.00019394</span>  <span class="number">0.00094537</span>  <span class="number">0.00884171</span>  <span class="number">0.00880042</span></span><br><span class="line">  <span class="number">0.00505424</span>  <span class="number">0.01009949</span>  <span class="number">0.01085199</span>  <span class="number">0.01027042</span>  <span class="number">0.01374666</span>  <span class="number">0.02776093</span></span><br><span class="line">  <span class="number">0.03155206</span>  <span class="number">0.03391963</span>  <span class="number">0.08474549</span>  <span class="number">0.08799973</span>  <span class="number">0.0083985</span>  <span class="number">-0.01724419</span></span><br><span class="line">  <span class="number">0.01399544</span>  <span class="number">0.01035839</span>  <span class="number">0.01004393</span>  <span class="number">0.0089306</span>   <span class="number">0.00902356</span>  <span class="number">0.00898983</span>]</span><br><span class="line">[<span class="number">703824.353689585</span>, <span class="number">688000.4130783302</span>, <span class="number">674508.5537976791</span>, <span class="number">662770.9045613626</span>]</span><br></pre></td></tr></table></figure>



<h3 id="392-395-epoch-lr-12-9"><a href="#392-395-epoch-lr-12-9" class="headerlink" title="392~395 epoch, lr=12-9"></a>392~395 epoch, lr=<code>12-9</code></h3><p>Let’s make w as the 3th epoch, and try tunning the lr smaller to <code>1e-9</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">174</span>]: w = W[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">175</span>]: lr = <span class="number">1e-9</span> <span class="comment"># learning rate</span></span><br><span class="line">     ...: iteration = <span class="number">5</span></span><br><span class="line">     ...: <span class="comment">#iterationRun(lr,iteration,x_data,y_data)</span></span><br><span class="line">     ...: <span class="comment">#w= &lt;last time&gt;</span></span><br><span class="line">     ...: L, W = iterationRun(lr,iteration,x_data,y_data,w)</span><br><span class="line">     ...: <span class="keyword">print</span> (str(L))</span><br><span class="line">     ...:</span><br><span class="line"><span class="number">0</span> : <span class="number">21</span>:<span class="number">41</span>:<span class="number">46.601560</span> L:<span class="number">661713.7975718635</span></span><br><span class="line"><span class="number">1</span> : <span class="number">21</span>:<span class="number">42</span>:<span class="number">16.607766</span> L:<span class="number">660793.0750887658</span></span><br><span class="line"><span class="number">2</span> : <span class="number">21</span>:<span class="number">42</span>:<span class="number">46.034783</span> L:<span class="number">663980.0848216356</span></span><br><span class="line"><span class="number">3</span> : <span class="number">21</span>:<span class="number">43</span>:<span class="number">15.439357</span> L:<span class="number">802745.540277066</span></span><br><span class="line"><span class="number">4</span> : <span class="number">21</span>:<span class="number">43</span>:<span class="number">45.015877</span> L:<span class="number">5429166.075156927</span></span><br><span class="line">[<span class="number">-6.16727255e-04</span>  <span class="number">1.00484493e-02</span>  <span class="number">9.93535744e-03</span>  <span class="number">9.93784427e-03</span></span><br><span class="line">  <span class="number">9.95911130e-03</span>  <span class="number">8.35499858e-03</span>  <span class="number">8.45588760e-03</span>  <span class="number">2.26448667e-03</span></span><br><span class="line">  <span class="number">1.22987564e-02</span>  <span class="number">2.16546844e-02</span>  <span class="number">9.10083843e-03</span>  <span class="number">9.03077135e-03</span></span><br><span class="line">  <span class="number">9.17185566e-03</span>  <span class="number">9.98181751e-03</span>  <span class="number">3.16708342e-03</span>  <span class="number">2.67366966e-03</span></span><br><span class="line">  <span class="number">8.41072713e-03</span>  <span class="number">8.73860126e-03</span> <span class="number">-2.03925361e-04</span>  <span class="number">1.00607272e-02</span></span><br><span class="line">  <span class="number">9.93460928e-03</span>  <span class="number">9.95365455e-03</span>  <span class="number">1.02829207e-02</span>  <span class="number">8.97031177e-03</span></span><br><span class="line">  <span class="number">9.31315565e-03</span>  <span class="number">1.65178857e-03</span>  <span class="number">1.03485940e-02</span>  <span class="number">2.12659601e-02</span></span><br><span class="line">  <span class="number">9.02198751e-03</span>  <span class="number">7.84152744e-03</span>  <span class="number">9.43025959e-03</span>  <span class="number">1.00085885e-02</span></span><br><span class="line">  <span class="number">8.87651196e-03</span>  <span class="number">4.98782391e-03</span>  <span class="number">8.55433776e-03</span>  <span class="number">8.78302430e-03</span></span><br><span class="line">  <span class="number">2.85369965e-04</span>  <span class="number">1.00635072e-02</span>  <span class="number">9.97046563e-03</span>  <span class="number">9.97461093e-03</span></span><br><span class="line">  <span class="number">1.04114813e-02</span>  <span class="number">9.36603695e-03</span>  <span class="number">9.88070916e-03</span>  <span class="number">1.43617060e-03</span></span><br><span class="line">  <span class="number">1.08629084e-02</span>  <span class="number">2.19977200e-02</span>  <span class="number">8.76197799e-03</span>  <span class="number">5.90977003e-03</span></span><br><span class="line">  <span class="number">9.62326853e-03</span>  <span class="number">1.00259754e-02</span>  <span class="number">1.06493535e-02</span>  <span class="number">5.41048668e-03</span></span><br><span class="line">  <span class="number">8.64521541e-03</span>  <span class="number">8.81179281e-03</span>  <span class="number">9.52186844e-04</span>  <span class="number">1.00684226e-02</span></span><br><span class="line">  <span class="number">1.00466367e-02</span>  <span class="number">1.00111076e-02</span>  <span class="number">1.08903525e-02</span>  <span class="number">1.07802435e-02</span></span><br><span class="line">  <span class="number">1.17922921e-02</span>  <span class="number">1.54851313e-03</span>  <span class="number">1.16898484e-02</span>  <span class="number">2.32874554e-02</span></span><br><span class="line">  <span class="number">8.68029225e-03</span>  <span class="number">3.18757813e-03</span>  <span class="number">9.62848850e-03</span>  <span class="number">1.00700956e-02</span></span><br><span class="line">  <span class="number">8.57625809e-03</span>  <span class="number">5.04569062e-03</span>  <span class="number">8.69887254e-03</span>  <span class="number">8.76585679e-03</span></span><br><span class="line">  <span class="number">1.72083560e-03</span>  <span class="number">1.00782383e-02</span>  <span class="number">1.01355162e-02</span>  <span class="number">1.00550971e-02</span></span><br><span class="line">  <span class="number">1.13226458e-02</span>  <span class="number">1.30078273e-02</span>  <span class="number">1.44589394e-02</span>  <span class="number">3.55086273e-03</span></span><br><span class="line">  <span class="number">1.51943562e-02</span>  <span class="number">2.65530997e-02</span>  <span class="number">8.80986381e-03</span>  <span class="number">3.28409285e-05</span></span><br><span class="line">  <span class="number">1.00950294e-02</span>  <span class="number">1.01279151e-02</span>  <span class="number">1.03012885e-02</span>  <span class="number">4.78865750e-03</span></span><br><span class="line">  <span class="number">8.69208729e-03</span>  <span class="number">8.78851492e-03</span>  <span class="number">2.74314457e-03</span>  <span class="number">1.00968105e-02</span></span><br><span class="line">  <span class="number">1.02776366e-02</span>  <span class="number">1.01066204e-02</span>  <span class="number">1.21105528e-02</span>  <span class="number">1.60772456e-02</span></span><br><span class="line">  <span class="number">1.82501496e-02</span>  <span class="number">7.85988030e-03</span>  <span class="number">2.23833884e-02</span>  <span class="number">3.24013740e-02</span></span><br><span class="line">  <span class="number">8.86125894e-03</span> <span class="number">-3.55036887e-03</span>  <span class="number">1.07979166e-02</span>  <span class="number">1.02065963e-02</span></span><br><span class="line">  <span class="number">7.53541740e-03</span>  <span class="number">6.99336995e-03</span>  <span class="number">8.72485483e-03</span>  <span class="number">8.79427710e-03</span></span><br><span class="line">  <span class="number">3.81308226e-03</span>  <span class="number">1.01212778e-02</span>  <span class="number">1.04463732e-02</span>  <span class="number">1.01606057e-02</span></span><br><span class="line">  <span class="number">1.29396336e-02</span>  <span class="number">1.98142376e-02</span>  <span class="number">2.27987403e-02</span>  <span class="number">1.48422348e-02</span></span><br><span class="line">  <span class="number">3.52605997e-02</span>  <span class="number">4.27051700e-02</span>  <span class="number">8.80287292e-03</span> <span class="number">-7.40948634e-03</span></span><br><span class="line">  <span class="number">1.17432739e-02</span>  <span class="number">1.02801699e-02</span>  <span class="number">8.42208402e-03</span>  <span class="number">6.63868882e-03</span></span><br><span class="line">  <span class="number">8.77476129e-03</span>  <span class="number">8.80978944e-03</span>  <span class="number">4.97591884e-03</span>  <span class="number">1.01527778e-02</span></span><br><span class="line">  <span class="number">1.06827453e-02</span>  <span class="number">1.02266089e-02</span>  <span class="number">1.37564839e-02</span>  <span class="number">2.43105168e-02</span></span><br><span class="line">  <span class="number">2.81161272e-02</span>  <span class="number">2.47089034e-02</span>  <span class="number">5.76241338e-02</span>  <span class="number">5.65673784e-02</span></span><br><span class="line">  <span class="number">8.51926553e-03</span> <span class="number">-1.12891688e-02</span>  <span class="number">1.28863403e-02</span>  <span class="number">1.03706768e-02</span></span><br><span class="line">  <span class="number">8.26939165e-03</span>  <span class="number">9.02047482e-03</span>  <span class="number">8.90751118e-03</span>  <span class="number">8.83629524e-03</span></span><br><span class="line">  <span class="number">6.10712791e-03</span>  <span class="number">1.01935224e-02</span>  <span class="number">1.09119304e-02</span>  <span class="number">1.02902353e-02</span></span><br><span class="line">  <span class="number">1.40567097e-02</span>  <span class="number">2.90486692e-02</span>  <span class="number">3.31514523e-02</span>  <span class="number">3.63020625e-02</span></span><br><span class="line">  <span class="number">8.90002712e-02</span>  <span class="number">9.21841280e-02</span>  <span class="number">8.33254748e-03</span> <span class="number">-1.43156605e-02</span></span><br><span class="line">  <span class="number">1.43210918e-02</span>  <span class="number">1.04713307e-02</span>  <span class="number">1.79200559e-02</span>  <span class="number">1.67676281e-02</span></span><br><span class="line">  <span class="number">9.09731287e-03</span>  <span class="number">9.03380699e-03</span>]</span><br><span class="line">[<span class="number">662770.9045613626</span>, <span class="number">661713.7975718635</span>, <span class="number">660793.0750887658</span>, <span class="number">663980.0848216356</span>, <span class="number">802745.540277066</span>, <span class="number">5429166.075156927</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">176</span>]: lossFunction(W[<span class="number">3</span>],x_data,y_data)</span><br><span class="line">Out[<span class="number">176</span>]: <span class="number">5429166.075156927</span></span><br></pre></td></tr></table></figure>

<p>This is really strange, while we got the w with L = <code>5429166.075156927</code> which looks overfitting( I guess ).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">190</span>]: lossFunction(w391,x_data,y_data)</span><br><span class="line">Out[<span class="number">190</span>]: <span class="number">662770.9037767164</span></span><br><span class="line">    </span><br><span class="line">In [<span class="number">192</span>]: lossFunction(w395,x_data,y_data)</span><br><span class="line">Out[<span class="number">192</span>]: <span class="number">5429166.071876905</span></span><br></pre></td></tr></table></figure>

<p>We could verify both w391 and w395 with public test data.</p>
<h2 id="Verify-w391-and-w395-with-testdata"><a href="#Verify-w391-and-w395-with-testdata" class="headerlink" title="Verify w391 and w395 with testdata"></a>Verify w391 and w395 with testdata</h2><h3 id="Processing-test-data"><a href="#Processing-test-data" class="headerlink" title="Processing test data"></a>Processing test data</h3><h4 id="test-csv"><a href="#test-csv" class="headerlink" title="test.csv"></a>test.csv</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># verify with test data test.csv</span></span><br><span class="line"><span class="comment"># preprocessing</span></span><br><span class="line"></span><br><span class="line">testDataList = list()</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"test.csv"</span>, newline=<span class="string">""</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line">    testData = csv.reader(csvfile, delimiter=<span class="string">","</span>,quotechar=<span class="string">"|"</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> testData:</span><br><span class="line">        testDataList.append(line[<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_data_test = [] <span class="comment"># 18*9 dimensions</span></span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line">listToAppend = list()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> testDataList:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> mod_18(i):</span><br><span class="line">        <span class="comment"># from mod 18: 0</span></span><br><span class="line">        listToAppend = [item]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> mod_18(i) == <span class="number">10</span>:</span><br><span class="line">        <span class="comment"># rain, consider "NR" = 0</span></span><br><span class="line">        listToAppend.append([<span class="string">"0"</span> <span class="keyword">if</span> x == <span class="string">'NR'</span> <span class="keyword">else</span> x <span class="keyword">for</span> x <span class="keyword">in</span> item])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> mod_18(i) == <span class="number">17</span>:</span><br><span class="line">        <span class="comment"># all 18 lines collected, built a set of data to extend</span></span><br><span class="line">        listToAppend.append(item)</span><br><span class="line">        x_data_test.append(T_list(listToAppend))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># append other data</span></span><br><span class="line">        listToAppend.append(item)</span><br><span class="line">    i = i + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">x_data_test = [np.array(X).reshape(<span class="number">1</span>,<span class="number">162</span>).astype(np.float).tolist()[<span class="number">0</span>] <span class="keyword">for</span> X <span class="keyword">in</span> x_data_test]</span><br><span class="line"></span><br><span class="line"><span class="comment">#x_data_test = [[float(j) for j in i[:18*9]] for i in x_data_test]</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">y</span><span class="params">(w,x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sum(w * x)</span><br><span class="line"></span><br><span class="line">y_data_w391 = [y(w391,x) <span class="keyword">for</span> x <span class="keyword">in</span> x_data_test ]</span><br><span class="line">y_data_w396 = [y(w396,x) <span class="keyword">for</span> x <span class="keyword">in</span> x_data_test ]</span><br></pre></td></tr></table></figure>

<h4 id="ans-csv"><a href="#ans-csv" class="headerlink" title="ans.csv"></a>ans.csv</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ans.csv</span></span><br><span class="line">answerTestDataList = list()</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"ans.csv"</span>, newline=<span class="string">""</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line">    testData = csv.reader(csvfile, delimiter=<span class="string">","</span>,quotechar=<span class="string">"|"</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> testData:</span><br><span class="line">        answerTestDataList.append(line[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>



<h3 id="Verify-data"><a href="#Verify-data" class="headerlink" title="Verify data"></a>Verify data</h3><p>It looks like the w391 is our best output :-) for now, and the w396 is overfitting!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">86</span>]: lossFunction(w391,x_data_test,y_answer)</span><br><span class="line">Out[<span class="number">86</span>]: <span class="number">40678.24250669469</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: lossFunction(w396,x_data_test,y_answer)</span><br><span class="line">Out[<span class="number">87</span>]: <span class="number">241252.78309255745</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">In [<span class="number">90</span>]: lossFunction(w388,x_data_test,y_answer)</span><br><span class="line">Out[<span class="number">90</span>]: <span class="number">45347.799286792215</span></span><br></pre></td></tr></table></figure>

<p>Draw the plot</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">y_w391 = np.array(y_data_w391)</span><br><span class="line">y_w396 = np.array(y_data_w396)</span><br><span class="line">y_answer = np.array(answerTestDataList[<span class="number">1</span>:]).astype(np.float)</span><br><span class="line">x = range(len(y_answer))</span><br><span class="line"></span><br><span class="line"><span class="comment"># refer to https://matplotlib.org/2.2.2/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py</span></span><br><span class="line"></span><br><span class="line">plt.plot(x, y_w391, label=<span class="string">"w391"</span>)</span><br><span class="line">plt.plot(x, y_w396, label=<span class="string">"w396"</span>)</span><br><span class="line">plt.plot(x, y_answer, label=<span class="string">"answer"</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">'240 test set'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'PM2.5'</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">"y_w391, y_w396 and y_answer"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>The plot is as below</p>
<img src="/ML-2017-fall-HW1-note/Figure_yW391_yW396_yAnswer.png" class="">



<h1 id="Start-studying-all-other-gradient-descent-alogrithm"><a href="#Start-studying-all-other-gradient-descent-alogrithm" class="headerlink" title="Start studying all other gradient descent alogrithm"></a>Start studying all other gradient descent alogrithm</h1><p>ref:<a href="http://ruder.io/optimizing-gradient-descent" target="_blank" rel="noopener">http://ruder.io/optimizing-gradient-descent</a></p>
<p>ref:<a href="https://www.slideshare.net/SebastianRuder/optimization-for-deep-learning" target="_blank" rel="noopener">https://www.slideshare.net/SebastianRuder/optimization-for-deep-learning</a></p>
<p>ref:<a href="https://zhuanlan.zhihu.com/p/22252270" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22252270</a></p>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><h3 id="Descent-speed"><a href="#Descent-speed" class="headerlink" title="Descent speed"></a>Descent speed</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">y_L_adagrad = np.array(L_adagrad[:<span class="number">391</span>])</span><br><span class="line">y_L_bgd = np.array(L_bgd[:<span class="number">391</span>])</span><br><span class="line">x = range(<span class="number">391</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># refer to https://matplotlib.org/2.2.2/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py</span></span><br><span class="line"></span><br><span class="line">plt.plot(x, y_L_adagrad, label=<span class="string">"Adagrade"</span>)</span><br><span class="line">plt.plot(x, y_L_bgd, label=<span class="string">"Batch Gradient Descent"</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">'390 epoch'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss Function Value'</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">"Batch GD and ADAGRAD"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="/ML-2017-fall-HW1-note/Figure_L_adagrad_vs_BGD_390.png" class="">

<p>It’s basically the same, the difference is only:</p>
<ul>
<li>in the very begining, ADAGRAD went to crazy field, while it self corrected to normal path soon</li>
<li>ADAGRAD will be converging slower than BGD …</li>
<li>our BGD was actually human tunned one, which means ADAGRAD is easier to find themself the correct path (no need for human invention)</li>
</ul>
<p>Also we could see the initial 30 epoch:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">8</span>]: initialN = <span class="number">30</span></span><br><span class="line">   ...: y_L_adagrad = np.array(L_adagrad[:initialN])</span><br><span class="line">   ...: y_L_bgd = np.array(L_bgd[:initialN])</span><br><span class="line">   ...: x = range(initialN)</span><br><span class="line">   ...:</span><br><span class="line">   ...:</span><br><span class="line">   ...: plt.plot(x, y_L_adagrad, label=<span class="string">"Adagrade"</span>)</span><br><span class="line">   ...: plt.plot(x, y_L_bgd, label=<span class="string">"Batch Gradient Descent"</span>)</span><br><span class="line">   ...:</span><br><span class="line">   ...: plt.xlabel(<span class="string">'390 epoch'</span>)</span><br><span class="line">   ...: plt.ylabel(<span class="string">'Loss Function Value'</span>)</span><br><span class="line">   ...:</span><br><span class="line">   ...: plt.title(<span class="string">"Batch GD and ADAGRAD"</span>)</span><br><span class="line">   ...:</span><br><span class="line">   ...: plt.legend()</span><br><span class="line">   ...: plt.show()</span><br><span class="line">   ...:</span><br></pre></td></tr></table></figure>

<img src="/ML-2017-fall-HW1-note/Figure_L_adagrad_vs_BGD_30.png" class="">

<h3 id="Verify-the-result"><a href="#Verify-the-result" class="headerlink" title="Verify the result"></a>Verify the result</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss function compare</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: lossFunction(w391,x_data_test,y_answer)</span><br><span class="line">Out[<span class="number">12</span>]: <span class="number">40678.24250669469</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: lossFunction(w_adagrad,x_data_test,y_answer)</span><br><span class="line">Out[<span class="number">13</span>]: <span class="number">50976.42462103875</span></span><br></pre></td></tr></table></figure>

<p>Check the prediction result figure</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">y_data_w391 = [y(w391,x) <span class="keyword">for</span> x <span class="keyword">in</span> x_data_test ]</span><br><span class="line">y_data_adagrad = [y(w_adagrad,x) <span class="keyword">for</span> x <span class="keyword">in</span> x_data_test ]</span><br><span class="line"></span><br><span class="line">y_w391 = np.array(y_data_w391)</span><br><span class="line">y_w_adagrad = np.array(y_data_adagrad)</span><br><span class="line">y_answer = np.array(answerTestDataList[<span class="number">1</span>:]).astype(np.float)</span><br><span class="line">x = range(len(y_answer))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(x, y_w391, label=<span class="string">"BGD"</span>)</span><br><span class="line">plt.plot(x, y_w_adagrad, label=<span class="string">"adagrad"</span>)</span><br><span class="line">plt.plot(x, y_answer, label=<span class="string">"answer"</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">'240 test set'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'PM2.5'</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">"BGD, adagrad and Answer"</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>



<img src="/ML-2017-fall-HW1-note/Figure_yBGD_yADAGRAD_yAnswer.png" class="">
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>Wey Gu | 古思为
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://note.siwei.info/ML-2017-fall-HW1-note/" title="ML 2017 fall homework1 Linear Regression 笔记">https://note.siwei.info/ML-2017-fall-HW1-note/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
              <a href="/tags/homework/" rel="tag"># homework</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/start-Using-hexo/" rel="prev" title="start Using hexo">
      <i class="fa fa-chevron-left"></i> start Using hexo
    </a></div>
      <div class="post-nav-item">
    <a href="/my-hhkb-and-macos-setup/" rel="next" title="my HHKB and macOS setup">
      my HHKB and macOS setup <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Gradient-Descent-for-linear-regression-task"><span class="nav-number">1.</span> <span class="nav-text">Gradient Descent for linear regression task</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-pre-processing"><span class="nav-number">1.1.</span> <span class="nav-text">Data pre processing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Loss-function"><span class="nav-number">1.2.</span> <span class="nav-text">Loss function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Iterations-for-grident-descent"><span class="nav-number">1.3.</span> <span class="nav-text">Iterations for grident descent</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tunning"><span class="nav-number">1.4.</span> <span class="nav-text">Tunning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Find-good-initial-learning-rate"><span class="nav-number">1.4.1.</span> <span class="nav-text">Find good initial learning rate</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lr-1e-10"><span class="nav-number">1.4.2.</span> <span class="nav-text">lr &#x3D; 1e-10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Run-10-20-epoch-lr-1e-10"><span class="nav-number">1.4.3.</span> <span class="nav-text">Run 10~20 epoch, lr&#x3D;1e-10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Run-20-30-epoch-lr-1e-10"><span class="nav-number">1.4.4.</span> <span class="nav-text">Run 20-30 epoch, lr&#x3D;1e-10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#30-200-epoch-lr-1e-10"><span class="nav-number">1.4.5.</span> <span class="nav-text">30~200 epoch, lr&#x3D;1e-10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#207-388-epoch-lr-2e-10"><span class="nav-number">1.4.6.</span> <span class="nav-text">207~388 epoch, lr&#x3D;2e-10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#388-391-epoch-lr-1e-8"><span class="nav-number">1.4.7.</span> <span class="nav-text">388~ 391 epoch, lr &#x3D;1e-8</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#392-395-epoch-lr-12-9"><span class="nav-number">1.4.8.</span> <span class="nav-text">392~395 epoch, lr&#x3D;12-9</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Verify-w391-and-w395-with-testdata"><span class="nav-number">1.5.</span> <span class="nav-text">Verify w391 and w395 with testdata</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Processing-test-data"><span class="nav-number">1.5.1.</span> <span class="nav-text">Processing test data</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#test-csv"><span class="nav-number">1.5.1.1.</span> <span class="nav-text">test.csv</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ans-csv"><span class="nav-number">1.5.1.2.</span> <span class="nav-text">ans.csv</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Verify-data"><span class="nav-number">1.5.2.</span> <span class="nav-text">Verify data</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Start-studying-all-other-gradient-descent-alogrithm"><span class="nav-number">2.</span> <span class="nav-text">Start studying all other gradient descent alogrithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Adagrad"><span class="nav-number">2.1.</span> <span class="nav-text">Adagrad</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Descent-speed"><span class="nav-number">2.1.1.</span> <span class="nav-text">Descent speed</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Verify-the-result"><span class="nav-number">2.1.2.</span> <span class="nav-text">Verify the result</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Wey Gu | 古思为"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Wey Gu | 古思为</p>
  <div class="site-description" itemprop="description">Build things.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/littlewey" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;littlewey" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:littlewey@gmail.com" title="E-Mail → mailto:littlewey@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/littlewey" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;littlewey" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/littlewey" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;littlewey" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/littlewey" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;littlewey" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/littlewey" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;littlewey" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i></a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wey Gu | 古思为</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '90bb84dab80e142752cb',
      clientSecret: '26f2fb897afc6becceae244ae33738ba8c51a0b7',
      repo        : 'littlewey.github.io',
      owner       : 'littlewey',
      admin       : ['littlewey'],
      id          : '90910cad14d72c487d307a7bbe88ebd0',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
